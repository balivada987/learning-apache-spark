<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Wenqiang Feng" />


<title>Latent Dirichlet Allocation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Learning Apache Spark</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Getting Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Installations</li>
    <li>
      <a href="install.html">Installations</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Integrate Spark</li>
    <li>
      <a href="pyspark-on-rodeo.html">Integrate spark with Rodeo</a>
    </li>
    <li>
      <a href="pyspark-on-jupyter.html">Integrate spark with Jupyter</a>
    </li>
    <li>
      <a href="spark-on-jetstream-cloud.html">Spark on jetstream cloud</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Data Preprocessing Template</li>
    <li>
      <a href="data-preprocessing-template.html">Data Preprocessing Template</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Wrangling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="data-manipulation.html">Basic DataFrame Manipulation</a>
    </li>
    <li>
      <a href="pyspark-vectors.html">Pyspark Vectors</a>
    </li>
    <li>
      <a href="featuresCol-and-labelCol.html">featuresCol &amp; labelCol</a>
    </li>
    <li>
      <a href="StringIndexer-and-VectorIndexer.html">StringIndexer &amp; VectorIndexer</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">pyspark.RDD object</li>
    <li>
      <a href="aggregate-function.html">Aggregate Functions</a>
    </li>
    <li>
      <a href="reduce-functions.html">Reduce Functions</a>
    </li>
    <li>
      <a href="HashingTF-and-CountVectorizer.html">HashingTF and CountVectorizer</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Regression</li>
    <li>
      <a href="linearRegression.html">Linear Regression</a>
    </li>
    <li>
      <a href="dttreeR.html">Decision tree Regression</a>
    </li>
    <li>
      <a href="randomforest.html">Random Forest Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Classification</li>
    <li>
      <a href="kmeans.html">Kmeans Classification</a>
    </li>
    <li>
      <a href="dttreeC.html">Decision tree Classification</a>
    </li>
    <li>
      <a href="randomforestC.html">Random Forest Classification</a>
    </li>
    <li>
      <a href="logistic-regression.html">Logistic Regression</a>
    </li>
    <li>
      <a href="svm.html">Support Vector Machine</a>
    </li>
    <li>
      <a href="naive-baye.html">Naive Bayes</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Neural Network</li>
    <li>
      <a href="fnn.html">Feedforward Neural Network</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Natural Language Processing</li>
    <li>
      <a href="nlpC.html">Text Classification</a>
    </li>
    <li>
      <a href="nlpLDA.html">Topic Model LDA</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Social Network Analysis</li>
    <li>
      <a href="sna.html">Social Network Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Module Tuning and Evaluation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Module Tuning</li>
    <li>
      <a href="regularization.html">Regularization</a>
    </li>
    <li>
      <a href="k-folds-cross-validation.html">K-folds Cross Validation</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/MingChen0919/learning-apache-spark">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/mingchen0919">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Latent Dirichlet Allocation</h1>
<h4 class="author"><em>Wenqiang Feng</em></h4>
<h4 class="date"><em>3/2/2017</em></h4>

</div>


<div id="remark" class="section level3">
<h3>Remark:</h3>
<ul>
<li>You can download the complete <a href="./ipynb/Natural%20Language%20Processing%20nb.ipynb">ipython notebook</a> for this tutorial session.</li>
<li>The <a href="https://www.youtube.com/watch?v=AsW0QzbYVow">YouTube video</a> should be useful for understanding this seesion.</li>
<li>The online textbook <a href="http://www.nltk.org/book/">Natural Language Processing with Python</a> is also useful.</li>
</ul>
</div>
<div id="preprocessing" class="section level2">
<h2>Preprocessing</h2>
<p>I always believe that better data often beats better algorithm.</p>
<ul>
<li>library required by the preprocessing</li>
</ul>
<pre class="python"><code>from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk import pos_tag
import string
import re
import langid</code></pre>
<ul>
<li>Convert to float format</li>
</ul>
<pre class="python"><code>def string_to_float(x):
    return float(x)</code></pre>
<ul>
<li>check to see if a row only contains whitespace</li>
</ul>
<pre class="python"><code>def check_blanks(data_str):
    is_blank = str(data_str.isspace())
    return is_blank</code></pre>
<ul>
<li>Determine whether the language of the text content is english or not: Use langid module to classify the language to make sure we are applying the correct cleanup actions for English <a href="https://github.com/saffsd/langid.py">langid</a></li>
</ul>
<pre class="python"><code>def check_lang(data_str):
    predict_lang = langid.classify(data_str)
    if predict_lang[1] &gt;= .9:
        language = predict_lang[0]
    else:
        language = &#39;NA&#39;
    return language</code></pre>
<ul>
<li>Remove features</li>
</ul>
<pre class="python"><code>def remove_features(data_str):
    # compile regex
    url_re = re.compile(&#39;https?://(www.)?\w+\.\w+(/\w+)*/?&#39;)
    punc_re = re.compile(&#39;[%s]&#39; % re.escape(string.punctuation))
    num_re = re.compile(&#39;(\\d+)&#39;)
    mention_re = re.compile(&#39;@(\w+)&#39;)
    alpha_num_re = re.compile(&quot;^[a-z0-9_.]+$&quot;)
    # convert to lowercase
    data_str = data_str.lower()
    # remove hyperlinks
    data_str = url_re.sub(&#39; &#39;, data_str)
    # remove @mentions
    data_str = mention_re.sub(&#39; &#39;, data_str)
    # remove puncuation
    data_str = punc_re.sub(&#39; &#39;, data_str)
    # remove numeric &#39;words&#39;
    data_str = num_re.sub(&#39; &#39;, data_str)
    # remove non a-z 0-9 characters and words shorter than 3 characters
    list_pos = 0
    cleaned_str = &#39;&#39;
    for word in data_str.split():
        if list_pos == 0:
            if alpha_num_re.match(word) and len(word) &gt; 2:
                cleaned_str = word
            else:
                cleaned_str = &#39; &#39;
        else:
            if alpha_num_re.match(word) and len(word) &gt; 2:
                cleaned_str = cleaned_str + &#39; &#39; + word
            else:
                cleaned_str += &#39; &#39;
        list_pos += 1
    return cleaned_str</code></pre>
<ul>
<li>removes stop words</li>
</ul>
<pre class="python"><code>def remove_stops(data_str):
    # expects a string
    stops = set(stopwords.words(&quot;english&quot;))
    list_pos = 0
    cleaned_str = &#39;&#39;
    text = data_str.split()
    for word in text:
        if word not in stops:
            # rebuild cleaned_str
            if list_pos == 0:
                cleaned_str = word
            else:
                cleaned_str = cleaned_str + &#39; &#39; + word
            list_pos += 1
    return cleaned_str</code></pre>
<ul>
<li>tagging text</li>
</ul>
<pre class="python"><code>def tag_and_remove(data_str):
    cleaned_str = &#39; &#39;
    # noun tags
    nn_tags = [&#39;NN&#39;, &#39;NNP&#39;, &#39;NNP&#39;, &#39;NNPS&#39;, &#39;NNS&#39;]
    # adjectives
    jj_tags = [&#39;JJ&#39;, &#39;JJR&#39;, &#39;JJS&#39;]
    # verbs
    vb_tags = [&#39;VB&#39;, &#39;VBD&#39;, &#39;VBG&#39;, &#39;VBN&#39;, &#39;VBP&#39;, &#39;VBZ&#39;]
    nltk_tags = nn_tags + jj_tags + vb_tags

    # break string into &#39;words&#39;
    text = data_str.split()

    # tag the text and keep only those with the right tags
    tagged_text = pos_tag(text)
    for tagged_word in tagged_text:
        if tagged_word[1] in nltk_tags:
            cleaned_str += tagged_word[0] + &#39; &#39;

    return cleaned_str</code></pre>
<ul>
<li>lemmatization</li>
</ul>
<pre class="python"><code>def lemmatize(data_str):
    # expects a string
    list_pos = 0
    cleaned_str = &#39;&#39;
    lmtzr = WordNetLemmatizer()
    text = data_str.split()
    tagged_words = pos_tag(text)
    for word in tagged_words:
        if &#39;v&#39; in word[1].lower():
            lemma = lmtzr.lemmatize(word[0], pos=&#39;v&#39;)
        else:
            lemma = lmtzr.lemmatize(word[0], pos=&#39;n&#39;)
        if list_pos == 0:
            cleaned_str = lemma
        else:
            cleaned_str = cleaned_str + &#39; &#39; + lemma
        list_pos += 1
    return cleaned_str</code></pre>
</div>
<div id="natural-language-processing-with-pyspark" class="section level2">
<h2>Natural Language Processing with PySpark</h2>
<div id="set-up-spark-context-and-sparksession" class="section level3">
<h3>1. Set up spark context and SparkSession</h3>
<pre class="python"><code>import pyspark
from pyspark.sql import SQLContext

# create spark contexts
sc = pyspark.SparkContext()
sqlContext = SQLContext(sc)

from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .appName(&quot;Python Spark Random Forest Regression&quot;) \
    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \
    .getOrCreate()</code></pre>
</div>
<div id="define-the-preprocessing-function-in-pyspark" class="section level3">
<h3>2. define the preprocessing function in PySpark</h3>
<pre class="python"><code>from pyspark.sql.functions import udf
from pyspark.sql.types import StringType
import preproc as pp

check_lang_udf = udf(pp.check_lang, StringType())
remove_stops_udf = udf(pp.remove_stops, StringType())
remove_features_udf = udf(pp.remove_features, StringType())
tag_and_remove_udf = udf(pp.tag_and_remove, StringType())
lemmatize_udf = udf(pp.lemmatize, StringType())
check_blanks_udf = udf(pp.check_blanks, StringType())</code></pre>
</div>
<div id="load-dataset" class="section level3">
<h3>3. load dataset</h3>
<pre class="python"><code>data_rdd = sc.textFile(&quot;data/nlpdata/raw_classified.txt&quot;)
parts_rdd = data_rdd.map(lambda l: l.split(&quot;\t&quot;))
# Filter bad rows out
garantee_col_rdd = parts_rdd.filter(lambda l: len(l) == 3)
typed_rdd = garantee_col_rdd.map(lambda p: (p[0], p[1], float(p[2])))
#Create DataFrame
data_df = sqlContext.createDataFrame(typed_rdd, [&quot;text&quot;, &quot;id&quot;, &quot;label&quot;])
#data_df.show()</code></pre>
<ul>
<li>shcek the schema</li>
</ul>
<pre class="python"><code>data_df.printSchema()</code></pre>
<pre class="python"><code># output
root
 |-- text: string (nullable = true)
 |-- id: string (nullable = true)
 |-- label: double (nullable = true)</code></pre>
<ul>
<li>preview the dataset</li>
</ul>
<pre class="python"><code>data_df.show(4)</code></pre>
<pre class="python"><code># output 
+--------------------+------------------+-----+
|                text|                id|label|
+--------------------+------------------+-----+
|Fresh install of ...|        1018769417|  1.0|
|Well. Now I know ...|       10284216536|  1.0|
|&quot;Literally six we...|       10298589026|  1.0|
|Mitsubishi i MiEV...|109017669432377344|  1.0|
+--------------------+------------------+-----+
only showing top 4 rows</code></pre>
</div>
<div id="preprocessing-1" class="section level3">
<h3>4. preprocessing</h3>
<ul>
<li>predict language and filter out those with less than 90% chance of being English</li>
</ul>
<pre class="python"><code>lang_df = data_df.withColumn(&quot;lang&quot;, check_lang_udf(data_df[&quot;text&quot;]))
en_df = lang_df.filter(lang_df[&quot;lang&quot;] == &quot;en&quot;)</code></pre>
<pre class="python"><code>en_df.printSchema()</code></pre>
<pre class="python"><code># ouput 
root
 |-- text: string (nullable = true)
 |-- id: string (nullable = true)
 |-- label: double (nullable = true)
 |-- lang: string (nullable = true)</code></pre>
<pre class="python"><code>en_df.show(4)</code></pre>
<pre class="python"><code>+--------------------+------------------+-----+----+
|                text|                id|label|lang|
+--------------------+------------------+-----+----+
|RT @goeentertain:...|665305154954989568|  1.0|  en|
|Teforia Uses Mach...|660668007975268352|  1.0|  en|
|   Apple TV or Roku?|       25842461136|  1.0|  en|
|Finished http://t...|        9412369614|  1.0|  en|
+--------------------+------------------+-----+----+
only showing top 4 rows</code></pre>
<ul>
<li>remove stop words</li>
</ul>
<pre class="python"><code>rm_stops_df = en_df.withColumn(&quot;stop_text&quot;, remove_stops_udf(en_df[&quot;text&quot;]))</code></pre>
<pre class="python"><code>rm_stops_df.printSchema()</code></pre>
<pre class="python"><code># output
root
 |-- text: string (nullable = true)
 |-- id: string (nullable = true)
 |-- label: double (nullable = true)
 |-- lang: string (nullable = true)
 |-- stop_text: string (nullable = true)</code></pre>
<pre class="python"><code>rm_stops_df.show(4)</code></pre>
<pre class="python"><code>#output
+--------------------+------------------+-----+----+--------------------+
|                text|                id|label|lang|           stop_text|
+--------------------+------------------+-----+----+--------------------+
|RT @goeentertain:...|665305154954989568|  1.0|  en|RT @goeentertain:...|
|Teforia Uses Mach...|660668007975268352|  1.0|  en|Teforia Uses Mach...|
|   Apple TV or Roku?|       25842461136|  1.0|  en|      Apple TV Roku?|
|Finished http://t...|        9412369614|  1.0|  en|Finished http://t...|
+--------------------+------------------+-----+----+--------------------+
only showing top 4 rows</code></pre>
<ul>
<li>remove features</li>
</ul>
<pre class="python"><code>rm_features_df = rm_stops_df.withColumn(&quot;feat_text&quot;, \
                                        remove_features_udf(rm_stops_df[&quot;stop_text&quot;]))</code></pre>
<pre class="python"><code>rm_features_df.printSchema()</code></pre>
<pre class="python"><code># output 
root
 |-- text: string (nullable = true)
 |-- id: string (nullable = true)
 |-- label: double (nullable = true)
 |-- lang: string (nullable = true)
 |-- stop_text: string (nullable = true)
 |-- feat_text: string (nullable = true)
</code></pre>
<pre class="python"><code>rm_features_df.show(4)</code></pre>
<pre class="python"><code>+--------------------+------------------+-----+----+--------------------+--------------------+
|                text|                id|label|lang|           stop_text|           feat_text|
+--------------------+------------------+-----+----+--------------------+--------------------+
|RT @goeentertain:...|665305154954989568|  1.0|  en|RT @goeentertain:...|  future blase   ...|
|Teforia Uses Mach...|660668007975268352|  1.0|  en|Teforia Uses Mach...|teforia uses mach...|
|   Apple TV or Roku?|       25842461136|  1.0|  en|      Apple TV Roku?|         apple  roku|
|Finished http://t...|        9412369614|  1.0|  en|Finished http://t...|            finished|
+--------------------+------------------+-----+----+--------------------+--------------------+
only showing top 4 rows
</code></pre>
<ul>
<li>tag the words remaining and keep only Nouns, Verbs and Adjectives</li>
</ul>
<pre class="python"><code>tagged_df = rm_features_df.withColumn(&quot;tagged_text&quot;, \
                                      tag_and_remove_udf(rm_features_df.feat_text))</code></pre>
<pre class="python"><code>tagged_df.printSchema()</code></pre>
<pre class="python"><code># ouput 
root
 |-- text: string (nullable = true)
 |-- id: string (nullable = true)
 |-- label: double (nullable = true)
 |-- lang: string (nullable = true)
 |-- stop_text: string (nullable = true)
 |-- feat_text: string (nullable = true)
 |-- tagged_text: string (nullable = true)</code></pre>
<pre class="python"><code>tagged_df.show(4)</code></pre>
<pre class="python"><code># output 
+--------------------+------------------+-----+----+--------------------+--------------------+--------------------+
|                text|                id|label|lang|           stop_text|           feat_text|         tagged_text|
+--------------------+------------------+-----+----+--------------------+--------------------+--------------------+
|RT @goeentertain:...|665305154954989568|  1.0|  en|RT @goeentertain:...|  future blase   ...| future blase vic...|
|Teforia Uses Mach...|660668007975268352|  1.0|  en|Teforia Uses Mach...|teforia uses mach...| teforia uses mac...|
|   Apple TV or Roku?|       25842461136|  1.0|  en|      Apple TV Roku?|         apple  roku|         apple roku |
|Finished http://t...|        9412369614|  1.0|  en|Finished http://t...|            finished|           finished |
+--------------------+------------------+-----+----+--------------------+--------------------+--------------------+
only showing top 4 rows</code></pre>
<ul>
<li>lemmatization of remaining words to reduce dimensionality &amp; boost measures</li>
</ul>
<pre class="python"><code>lemm_df = tagged_df.withColumn(&quot;lemm_text&quot;, lemmatize_udf(tagged_df[&quot;tagged_text&quot;]))</code></pre>
<ul>
<li>remove all rows containing only blank spaces</li>
</ul>
<pre class="python"><code>check_blanks_df = lemm_df.withColumn(&quot;is_blank&quot;, check_blanks_udf(lemm_df[&quot;lemm_text&quot;]))
no_blanks_df = check_blanks_df.filter(check_blanks_df[&quot;is_blank&quot;] == &quot;False&quot;)
no_blanks_df.printSchema()</code></pre>
<pre class="python"><code># output 
root
 |-- text: string (nullable = true)
 |-- id: string (nullable = true)
 |-- label: double (nullable = true)
 |-- lang: string (nullable = true)
 |-- stop_text: string (nullable = true)
 |-- feat_text: string (nullable = true)
 |-- tagged_text: string (nullable = true)
 |-- lemm_text: string (nullable = true)
 |-- is_blank: string (nullable = true)</code></pre>
<pre class="python"><code>no_blanks_df = no_blanks_df.withColumn(&quot;text&quot;,no_blanks_df.lemm_text)</code></pre>
<ul>
<li>remove duplicate records</li>
</ul>
<pre class="python"><code>dedup_df = no_blanks_df.dropDuplicates([&#39;text&#39;, &#39;label&#39;])</code></pre>
<ul>
<li>extract the useful columns</li>
</ul>
<pre class="python"><code>data_set = dedup_df.select(&#39;id&#39;, &#39;text&#39;,&#39;label&#39;)</code></pre>
<ul>
<li>preview the clean data</li>
</ul>
<pre class="python"><code>data_set.show(4)</code></pre>
<pre class="python"><code># output 
+------------------+--------------------+-----+
|                id|                text|label|
+------------------+--------------------+-----+
|        1546813742|              dragon|  1.0|
|        1558492525|           hurt much|  1.0|
|383221484023709697|seth blog word se...|  1.0|
|660668007975268352|teforia use machi...|  1.0|
+------------------+--------------------+-----+
only showing top 4 rows</code></pre>
</div>
<div id="splitting-data-to-train-and-test-datasets" class="section level3">
<h3>5. splitting data to train and test datasets</h3>
<pre class="python"><code># Split the data into training and test sets (40% held out for testing)
(trainingData, testData) = data_set.randomSplit([0.6, 0.4], seed=1234)</code></pre>
</div>
<div id="machine-learning" class="section level3">
<h3>6. Machine learning</h3>
<ul>
<li>load required library</li>
</ul>
<pre class="python"><code>from pyspark.ml.feature import HashingTF, IDF, Tokenizer
from pyspark.ml import Pipeline
from pyspark.ml.classification import NaiveBayes, RandomForestClassifier 
from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.tuning import CrossValidator
from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer</code></pre>
<ul>
<li>Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and rf (Random Forest).</li>
</ul>
<pre class="python"><code># Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.
tokenizer = Tokenizer(inputCol=&quot;text&quot;, outputCol=&quot;words&quot;)
hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=&quot;features&quot;)
idf = IDF(minDocFreq=3, inputCol=&quot;features&quot;, outputCol=&quot;idf&quot;)</code></pre>
<ul>
<li>Random Forest</li>
</ul>
<pre class="python"><code>rf = RandomForestClassifier(numTrees=100,maxDepth=10)</code></pre>
<ul>
<li>pipline</li>
</ul>
<pre class="python"><code>pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, rf])</code></pre>
<ul>
<li>Train model. This also runs the indexers.</li>
</ul>
<pre class="python"><code># Train model.  This also runs the indexers.
model = pipeline.fit(trainingData)</code></pre>
<ul>
<li>Make predictions.</li>
</ul>
<pre class="python"><code>predictions = model.transform(testData)</code></pre>
<ul>
<li>preview the prediction</li>
</ul>
<pre class="python"><code>predictions.select(&quot;text&quot;, &quot;label&quot;, &quot;prediction&quot;).show(5)</code></pre>
<pre class="python"><code># ouput 
+--------------------+-----+----------+
|                text|label|prediction|
+--------------------+-----+----------+
|teforia use machi...|  1.0|       1.0|
|future blase vice...|  1.0|       1.0|
|meet rolo dogsoft...|  1.0|       1.0|
|meet jet dogsofth...|  1.0|       1.0|
|                 hot|  1.0|       1.0|
+--------------------+-----+----------+
only showing top 5 rows</code></pre>
<ul>
<li>evaluate the model</li>
</ul>
<pre class="python"><code>from pyspark.ml.evaluation import MulticlassClassificationEvaluator
evaluator = MulticlassClassificationEvaluator(predictionCol=&quot;prediction&quot;)
evaluator.evaluate(predictions)</code></pre>
<pre class="python"><code># output
0.8272058823529411</code></pre>
</div>
</div>

<center>Copyright &copy; 2017 Ming Chen  & Wenqiang Feng. All rights reserved.</center>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
