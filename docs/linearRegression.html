<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Wenqiang Feng &amp; Ming Chen" />


<title>Linear Regression</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Learning Apache Spark</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Getting Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Installations</li>
    <li>
      <a href="install.html">Installations</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Integrate Spark</li>
    <li>
      <a href="pyspark-on-rodeo.html">Integrate spark with Rodeo</a>
    </li>
    <li>
      <a href="pyspark-on-jupyter.html">Integrate spark with Jupyter</a>
    </li>
    <li>
      <a href="spark-on-jetstream-cloud.html">Spark on jetstream cloud</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Data Preprocessing Template</li>
    <li>
      <a href="data-preprocessing-template.html">Data Preprocessing Template</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Data Wrangling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="data-manipulation.html">Basic DataFrame Manipulation</a>
    </li>
    <li>
      <a href="pyspark-vectors.html">Pyspark Vectors</a>
    </li>
    <li>
      <a href="featuresCol-and-labelCol.html">featuresCol &amp; labelCol</a>
    </li>
    <li>
      <a href="StringIndexer-and-VectorIndexer.html">StringIndexer &amp; VectorIndexer</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">pyspark.RDD object</li>
    <li>
      <a href="aggregate-function.html">Aggregate Functions</a>
    </li>
    <li>
      <a href="reduce-functions.html">Reduce Functions</a>
    </li>
    <li>
      <a href="HashingTF-and-CountVectorizer.html">HashingTF and CountVectorizer</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Regression</li>
    <li>
      <a href="linearRegression.html">Linear Regression</a>
    </li>
    <li>
      <a href="dttreeR.html">Decision tree Regression</a>
    </li>
    <li>
      <a href="randomforest.html">Random Forest Regression</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Classification</li>
    <li>
      <a href="kmeans.html">Kmeans Classification</a>
    </li>
    <li>
      <a href="dttreeC.html">Decision tree Classification</a>
    </li>
    <li>
      <a href="randomforestC.html">Random Forest Classification</a>
    </li>
    <li>
      <a href="logistic-regression.html">Logistic Regression</a>
    </li>
    <li>
      <a href="svm.html">Support Vector Machine</a>
    </li>
    <li>
      <a href="naive-baye.html">Naive Bayes</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Neural Network</li>
    <li>
      <a href="fnn.html">Feedforward Neural Network</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Natural Language Processing</li>
    <li>
      <a href="nlpC.html">Text Classification</a>
    </li>
    <li>
      <a href="nlpLDA.html">Topic Model LDA</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Social Network Analysis</li>
    <li>
      <a href="sna.html">Social Network Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    Module Tuning and Evaluation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="divider"></li>
    <li class="dropdown-header">Module Tuning</li>
    <li>
      <a href="regularization.html">Regularization</a>
    </li>
    <li>
      <a href="k-folds-cross-validation.html">K-folds Cross Validation</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/MingChen0919/learning-apache-spark">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/mingchen0919">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Linear Regression</h1>
<h4 class="author"><em>Wenqiang Feng &amp; Ming Chen</em></h4>
<h4 class="date"><em>2/17/2017</em></h4>

</div>


<div id="remark" class="section level3">
<h3>Remark:</h3>
<ul>
<li><p>You can download the complete <a href="./ipynb/Regression.ipynb">ipython notebook</a> and <a href="./ipynb/LinearRegression.ipynb">ipython notebook (pipline version)</a> for the this session.</p></li>
<li><p>More details can be found on the offical website for <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression">pyspark.ml package</a>.</p></li>
</ul>
</div>
<div id="set-up-spark-context-and-sparksession" class="section level3">
<h3>1. Set up spark context and SparkSession</h3>
<pre class="python"><code>from pyspark import SparkConf, SparkContext
## set up spark context
from pyspark.sql import SQLContext
sc = SparkContext()
sqlContext = SQLContext(sc)
## set up  SparkSession
from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .appName(&quot;Python Spark SQL basic example&quot;) \
    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \
    .getOrCreate()</code></pre>
</div>
<div id="load-dataset" class="section level3">
<h3>2. Load dataset</h3>
<pre class="python"><code>df = sqlContext.read.format(&#39;com.databricks.spark.csv&#39;).\
                               options(header=&#39;true&#39;, \
                               inferschema=&#39;true&#39;).load(&quot;./data/Advertising.csv&quot;,header=True);</code></pre>
<pre class="python"><code>df.take(2)
df.printSchema()</code></pre>
<pre class="python"><code>root
 |-- _c0: integer (nullable = true)
 |-- TV: double (nullable = true)
 |-- Radio: double (nullable = true)
 |-- Newspaper: double (nullable = true)
 |-- Sales: double (nullable = true)</code></pre>
</div>
<div id="convert-the-data-to-dense-vector" class="section level3">
<h3>3. Convert the data to dense vector</h3>
<pre class="python"><code>from pyspark.sql import Row
from pyspark.ml.linalg import Vectors</code></pre>
<pre class="python"><code># convert the data to dense vector
def transData(data):
    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&#39;features&#39;,&#39;label&#39;])</code></pre>
</div>
<div id="transform-the-dataset-to-dataframe" class="section level3">
<h3>4. Transform the dataset to DataFrame</h3>
<pre class="python"><code>transformed= transData(df)
transformed.show()</code></pre>
<pre class="python"><code>+-----------------+-----+
|         features|label|
+-----------------+-----+
|[230.1,37.8,69.2]| 22.1|
| [44.5,39.3,45.1]| 10.4|
| [17.2,45.9,69.3]|  9.3|
|[151.5,41.3,58.5]| 18.5|
|[180.8,10.8,58.4]| 12.9|
|  [8.7,48.9,75.0]|  7.2|
| [57.5,32.8,23.5]| 11.8|
|[120.2,19.6,11.6]| 13.2|
|    [8.6,2.1,1.0]|  4.8|
| [199.8,2.6,21.2]| 10.6|
|  [66.1,5.8,24.2]|  8.6|
| [214.7,24.0,4.0]| 17.4|
| [23.8,35.1,65.9]|  9.2|
|   [97.5,7.6,7.2]|  9.7|
|[204.1,32.9,46.0]| 19.0|
|[195.4,47.7,52.9]| 22.4|
|[67.8,36.6,114.0]| 12.5|
|[281.4,39.6,55.8]| 24.4|
| [69.2,20.5,18.3]| 11.3|
|[147.3,23.9,19.1]| 14.6|
+-----------------+-----+
only showing top 20 rows</code></pre>
</div>
<div id="fit-model-ridge-regression-and-the-lasso" class="section level3">
<h3>5. Fit model (Ridge Regression and the LASSO)</h3>
<pre class="python"><code># Import LinearRegression class
from pyspark.ml.regression import LinearRegression

# Define LinearRegression algorithm
lr = LinearRegression()

# Fit 2 models, using different regularization parameters
modelA = lr.fit(transformed, {lr.regParam:0.0})
modelB = lr.fit(transformed, {lr.regParam:1.0})</code></pre>
</div>
<div id="evaluation" class="section level3">
<h3>6. Evaluation</h3>
<pre class="python"><code> # Make predictions
predictionsA = modelA.transform(transformed)
predictionsA.show()</code></pre>
<pre class="python"><code>+-----------------+-----+------------------+
|         features|label|        prediction|
+-----------------+-----+------------------+
|[230.1,37.8,69.2]| 22.1| 20.52397440971517|
| [44.5,39.3,45.1]| 10.4|12.337854820894362|
| [17.2,45.9,69.3]|  9.3|12.307670779994238|
|[151.5,41.3,58.5]| 18.5| 17.59782951168913|
|[180.8,10.8,58.4]| 12.9|13.188671856831299|
|  [8.7,48.9,75.0]|  7.2|12.478347634035858|
| [57.5,32.8,23.5]| 11.8|11.729759951563684|
|[120.2,19.6,11.6]| 13.2| 12.12295316550228|
|    [8.6,2.1,1.0]|  4.8| 3.727340862861585|
| [199.8,2.6,21.2]| 10.6|12.550848722934685|
|  [66.1,5.8,24.2]|  8.6| 7.032299200558857|
| [214.7,24.0,4.0]| 17.4| 17.28512918260026|
| [23.8,35.1,65.9]|  9.2|10.577120733627675|
|   [97.5,7.6,7.2]|  9.7| 8.826300480033199|
|[204.1,32.9,46.0]| 19.0|18.434366383561077|
|[195.4,47.7,52.9]| 22.4|20.819299516495455|
|[67.8,36.6,114.0]| 12.5| 12.82365674369938|
|[281.4,39.6,55.8]| 24.4|23.224957158799008|
| [69.2,20.5,18.3]| 11.3| 9.951682059118799|
|[147.3,23.9,19.1]| 14.6|14.166072932273261|
+-----------------+-----+------------------+
only showing top 20 rows</code></pre>
<pre class="python"><code>predictionsB = modelB.transform(transformed)
predictionsB.show()</code></pre>
<pre class="python"><code>+-----------------+-----+------------------+
|         features|label|        prediction|
+-----------------+-----+------------------+
|[230.1,37.8,69.2]| 22.1| 19.76875575831641|
| [44.5,39.3,45.1]| 10.4|12.681934421326527|
| [17.2,45.9,69.3]|  9.3|12.831279878059057|
|[151.5,41.3,58.5]| 18.5|17.212685096576116|
|[180.8,10.8,58.4]| 12.9|13.565646466441844|
|  [8.7,48.9,75.0]|  7.2|13.013004013254886|
| [57.5,32.8,23.5]| 11.8|12.015109427517054|
|[120.2,19.6,11.6]| 13.2|12.282357116553044|
|    [8.6,2.1,1.0]|  4.8|  5.16673805973666|
| [199.8,2.6,21.2]| 10.6|12.755472584548897|
|  [66.1,5.8,24.2]|  8.6| 8.123762036616027|
| [214.7,24.0,4.0]| 17.4| 16.56110418166338|
| [23.8,35.1,65.9]|  9.2|11.370966908074013|
|   [97.5,7.6,7.2]|  9.7| 9.497791423923593|
|[204.1,32.9,46.0]| 19.0|17.838038564514186|
|[195.4,47.7,52.9]| 22.4|19.868060781684964|
|[67.8,36.6,114.0]| 12.5|13.636219112847762|
|[281.4,39.6,55.8]| 24.4| 21.93487824178411|
| [69.2,20.5,18.3]| 11.3|10.503997287424209|
|[147.3,23.9,19.1]| 14.6|14.052394030313582|
+-----------------+-----+------------------+
only showing top 20 rows</code></pre>
<pre class="python"><code>RMSE = evaluator.evaluate(predictionsB)
print(&quot;ModelB: Root Mean Squared Error = &quot; + str(RMSE))</code></pre>
</div>
<div id="visualization" class="section level3">
<h3>7. Visualization</h3>
<pre class="python"><code># Import numpy, pandas, and ggplot
import numpy as np
from pandas import *
from ggplot import *
 
# Create Python DataFrame
pop = transformed.rdd.map(lambda p: (p.features[0])).collect()
sales = transformed.rdd.map(lambda p: (p.label)).collect()
predA = predictionsA.select(&quot;prediction&quot;).rdd.map(lambda r: r[0]).collect()
predB = predictionsB.select(&quot;prediction&quot;).rdd.map(lambda r: r[0]).collect()



pydf = DataFrame([predA]) 
nx,ny = pydf.shape
type1 = Series([0 for x in range(ny)])
type2 = Series([1 for x in range(ny)])

#pydf
# pandas DataFrame    
pydf1 = DataFrame({&#39;pop&#39;:pop,&#39;sales&#39;:sales,&#39;pred&#39;:predA,&#39;type&#39;:type1})
pydf2 = DataFrame({&#39;pop&#39;:pop,&#39;sales&#39;:sales,&#39;pred&#39;:predB,&#39;type&#39;:type2})

frames = [pydf1, pydf2]

result = pd.concat(frames)
result[&#39;type&#39;] = result[&#39;type&#39;].astype(object)
result</code></pre>
<pre class="python"><code># Create scatter plot and two regression models (scaling exponential) using ggplot
ggplot(result, aes(x=&#39;pop&#39;,y=&#39;pred&#39;,color=&#39;type&#39;)) +\
geom_point(colors=&#39;blue&#39;) </code></pre>
<div id="more-features-about-the-model" class="section level4">
<h4>8. More features about the model</h4>
<ul>
<li>build model</li>
</ul>
<pre class="python"><code>from pyspark.ml.linalg import Vectors
df = sqlContext.read.format(&#39;com.databricks.spark.csv&#39;).\
                               options(header=&#39;true&#39;, \
                               inferschema=&#39;true&#39;).load(&quot;./data/Advertising.csv&quot;,header=True);</code></pre>
<pre class="python"><code># convert the data to dense vector
def transData(data):
    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&#39;features&#39;,&#39;label&#39;])</code></pre>
<pre class="python"><code>transformed= transData(df)
#transformed.show()</code></pre>
<pre class="python"><code>lr = LinearRegression(maxIter=5, regParam=0.0, solver=&quot;normal&quot;)</code></pre>
<ul>
<li>fit model</li>
</ul>
<pre class="python"><code>model = lr.fit(transformed)</code></pre>
<ul>
<li>coefficients</li>
</ul>
<pre class="python"><code>model.coefficients</code></pre>
<pre class="python"><code>DenseVector([0.0458, 0.1885, -0.001])</code></pre>
<ul>
<li>intercept</li>
</ul>
<pre class="python"><code>model.intercept</code></pre>
<pre class="python"><code>2.9388893694594134</code></pre>
<ul>
<li>summary</li>
</ul>
<pre class="python"><code>def modelsummary(model):
    import numpy as np
    print &quot;##&quot;,&quot;Note: the last rows are the information for Intercept&quot;
    print &quot;##&quot;,&quot;-------------------------------------------------&quot;
    print &quot;##&quot;,&quot;  Estimate  Std.Error  t Values  P-value&quot;
    coef = np.append(list(model.coefficients),model.intercept)
    Summary=model.summary
    
    for i in range(len(Summary.pValues)):
        print &quot;##&quot;,&#39;{:10.6f}&#39;.format(coef[i]),\
        &#39;{:10.6f}&#39;.format(Summary.coefficientStandardErrors[i]),\
        &#39;{:8.3f}&#39;.format(Summary.tValues[i]),\
        &#39;{:10.6f}&#39;.format(Summary.pValues[i])
        
    print &quot;##&quot;,&#39;---&#39;
    print &quot;##&quot;,&quot;Mean squared error: % .6f&quot; % Summary.meanSquaredError, &quot;, RMSE: % .6f&quot; % Summary.rootMeanSquaredError 
    print &quot;##&quot;,&quot;Multiple R-squared: %f&quot; % Summary.r2, &quot;, Total iterations: %i&quot;% Summary.totalIterations       </code></pre>
<pre class="python"><code>modelsummary(model)</code></pre>
<pre><code>## Note: the last rows are the information for Intercept
## -------------------------------------------------
##   Estimate  Std.Error  t Values  P-value
##   0.045765   0.001395   32.809   0.000000
##   0.188530   0.008611   21.893   0.000000
##  -0.001037   0.005871   -0.177   0.859915
##   2.938889   0.311908    9.422   0.000000
## ---
## Mean squared error:  2.784126 , RMSE:  1.668570
## Multiple R-squared: 0.897211 , Total iterations: 1</code></pre>
<ul>
<li>save and extract model</li>
</ul>
<pre class="python"><code>temp_path = &#39;temp/Users/wenqiangfeng/Dropbox/Spark/Code/model&#39;
modelPath = temp_path + &quot;/lr_model&quot;</code></pre>
<pre class="python"><code>model.save(modelPath)</code></pre>
<pre class="python"><code>lr2 = model.load(modelPath)</code></pre>
<ul>
<li>check the loaded model</li>
</ul>
<pre class="python"><code>lr2.coefficients</code></pre>
<pre class="python"><code>DenseVector([0.0458, 0.1885, -0.001])</code></pre>
</div>
<div id="comparsion-with-r" class="section level4">
<h4>9. Comparsion with R</h4>
<pre class="r"><code>data &lt;- read.csv(&quot;./data/Advertising.csv&quot;, header = TRUE)</code></pre>
<pre class="r"><code>fit1 = lm(Sales~.,data = data)
summary(fit1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sales ~ ., data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.8277 -0.8908  0.2418  1.1893  2.8292 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
## TV           0.045765   0.001395  32.809   &lt;2e-16 ***
## Radio        0.188530   0.008611  21.893   &lt;2e-16 ***
## Newspaper   -0.001037   0.005871  -0.177     0.86    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.686 on 196 degrees of freedom
## Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 
## F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>par(mfrow=c(2,2))
plot(fit1)</code></pre>
<p><img src="linearRegression_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
</div>
</div>

<center>Copyright &copy; 2017 Ming Chen  & Wenqiang Feng. All rights reserved.</center>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
